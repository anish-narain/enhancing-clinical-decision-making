# Enhancing Clinical Decision Making with Interpretable AI

## Files In This Repository
| Folder | Description |
| --------------- | --------------- |
| `identifying-ARDS` | <ol><li>`data-preprocessing`: Contains Google BigQuery scripts used to extract patient notes, concepts and features from MIMIC-IV's hosp, icu, notes, and ECG modules to identify ARDs.</li><li>`resources`: Contains the background information on the cohort selection process conducted by Dr. Dominic Marshall.</li><li>`cbm-work`: Contains the concept bottleneck models (CBMs) used to identify ARDS. It includes both the original (vanilla) CBMs and the enhanced CBMs. The enhanced CBMs share the same architecture as the vanilla CBMs, but their concept set is augmented with additional concept labels generated by a large language model (LLM).</li><li>`llm-work`: Contains experiments conducted to identify a language model (LLM) and prompt structure for extracting additional concept labels for the ARDS patient cohort from their discharge summaries, radiology reports, and ECD notes. It also includes attempts to scale the LLM inference to a large cohort of patients and the final successful implementation of scaling up on Google Colab.</li><li>`report-experiments`: Contains code for generating the plots used in the final thesis and for creating the regression baseline for comparison. It also includes code for calculating additional metrics, such as the completeness score.</li></ol> |
| `predicting-mortality` | <ol><li>`data-preprocessing`: Contains Google BigQuery scripts used to extract concepts and features from MIMIC-IV's hosp and icu modules for predicting mortality.</li><li>`cbm-work`: Contains the concept bottleneck models (CBMs) used to predict mortality.</li><li>`report-experiments`: Contains code for generating the plots used in the final thesis and for creating the regression baseline for comparison.</li></ol> |
| `preliminary-work` | <ol><li>`basic-cbms`: Contains initial code for training a concept bottleneck model using dummy data to get familiar with the process.</li><li>`basic-llms`: Contains initial attempt at LLM fine-tuning.</li><li>`mimic-querying`: Contains initial scripts for processing MIMIC-IV notes.</li></ol> |
| `resources` | <ol><li>`readme.md`: Contains the papers I read and resources I found useful throughout this project.</li><li>interim-report: Submitted May 3rd, 2024. (WILL ADD AFTER GRADING)</li><li>final-thesis: Submitted June 21st, 2024. (WILL ADD AFTER GRADING)</li><li>poster: Presented June 27th, 2024. (WILL ADD AFTER GRADING)</li></ol> |

More details can be found in the markdown files within the subfolders.

## Requirements
### Dataset 
To create the datasets for the [mortality prediction](https://github.com/anish-narain/final-year-project/tree/main/predicting-mortality/data-preprocessing) and [ARDS identification task](https://github.com/anish-narain/final-year-project/tree/main/identifying-ARDS/data-preprocessing), Google BigQuery is needed. Here is an [overview](https://github.com/anish-narain/final-year-project/tree/main/resources#2-mimic-resources). 
### Concept Bottleneck Model
All the CBM code for this project should be run on Google Colab. First, create the required dataset using BigQuery. Then, upload the resulting CSV file to the main directory of the Colab session before running the code.
### Large Language Model 
To run the LLM code locally, `ollama` and `LangChain` needs to be installed. Additionally, once Ollama is installed, the LLM required for inference must be downloaded using either the `ollama pull` or `ollama run` command.
