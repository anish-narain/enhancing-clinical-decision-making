{"cells":[{"cell_type":"markdown","metadata":{"id":"yQKhJRomHFbv"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4377,"status":"ok","timestamp":1717679478395,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"TfP7ZOjVDpOx","outputId":"0b90b869-043a-4e43-e4d8-d07721e8e121"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Downloading ollama...\n","############################################################################################# 100.0%\n",">>> Installing ollama to /usr/local/bin...\n",">>> Creating ollama user...\n",">>> Adding ollama user to video group...\n",">>> Adding current user to ollama group...\n",">>> Creating ollama systemd service...\n","WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n"]}],"source":["!curl -fsSL https://ollama.com/install.sh | sh"]},{"cell_type":"markdown","metadata":{"id":"rM95jNBdHI0r"},"source":["Inside terminal run the following:\n","\n","```\n","ollama serve &\n","ollama run llama3\n","```\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12613,"status":"ok","timestamp":1717680093298,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"9IAbyW5pF9zY","outputId":"47186cf9-6866-4d9e-8b1a-2f56dd5490a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_community\n","  Downloading langchain_community-0.2.3-py3-none-any.whl (2.2 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m2.1/2.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n","Collecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n","  Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n","  Downloading langchain_core-0.2.4-py3-none-any.whl (310 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n","  Downloading langsmith-0.1.74-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n","  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.3)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.2 langchain-core-0.2.4 langchain-text-splitters-0.2.1 langchain_community-0.2.3 langsmith-0.1.74 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain_community"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27167,"status":"ok","timestamp":1717680125403,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"jun0nrA0GrLT","outputId":"86ae35f3-0b58-45f1-ef59-92e006a3c7cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Load Google Drive because it stores /content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"oNaOPG2qHCqK"},"source":["# Imports"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1388,"status":"ok","timestamp":1717680637987,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"19dvIgvgGKyZ"},"outputs":[],"source":["import pandas as pd\n","import time\n","import random\n","import csv\n","from langchain_community.llms import Ollama\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain_core.prompts import PromptTemplate"]},{"cell_type":"markdown","metadata":{"id":"AiAf0b-iHdww"},"source":["# Functions to load data, specify LLM prompt, and perform LLM inference"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717680643600,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"ZpdcyLsmHbE6"},"outputs":[],"source":["def load_data(file_path):\n","    df = pd.read_csv(file_path)\n","    df.fillna('', inplace=True)\n","    return df\n","\n","def select_random_start(num_rows, min_rows=15):\n","    if num_rows < min_rows:\n","        raise ValueError(f\"The dataset must contain at least {min_rows} rows to process.\")\n","    return random.randint(0, num_rows - min_rows)\n","\n","def create_prompt_template():\n","    return PromptTemplate(\n","        template=(\n","            \"Context: You are a clinician receiving chunks of clinical text for patients in an ICU. Please do the reviewing as quickly as possible.\\n\"\n","            \"Task: Determine if the patient suffered from aspiration.\\n\"\n","            \"Instructions: Answer with 'Yes' or 'No'. If there is not enough information, answer 'No'.\\n\"\n","            \"Discharge Text:\\n{discharge_text}\\n\\n\"\n","            \"Query: Does the chunk of text mention that the patient suffered from aspiration? Answer strictly in 'Yes' or 'No'.\"\n","        ),\n","        input_variables=[\"discharge_text\"]\n","    )\n","\n","def chunk_text(text, chunk_size, overlap):\n","    start = 0\n","    chunks = []\n","    while start < len(text):\n","        end = start + chunk_size\n","        chunks.append(text[start:end])\n","        start += chunk_size - overlap\n","    return chunks\n","\n","def check_for_aspiration(discharge_text, llm, prompt_template, chunk_size, chunk_overlap):\n","    chunks = chunk_text(discharge_text, chunk_size, chunk_overlap)\n","    results = []\n","    for chunk in chunks:\n","        prompt = prompt_template.format(discharge_text=chunk)\n","        try:\n","            response = llm.invoke(prompt)\n","            results.append(response.strip())\n","        except Exception as e:\n","            results.append(f\"Error invoking model: {e}\")\n","    aspiration_mentions = [res for res in results if \"Yes\" in res]\n","    if aspiration_mentions:\n","        return \"Yes\", aspiration_mentions[0], len(discharge_text) # Return aspiration result, explanation, and length of discharge_text\n","    else:\n","        return \"No\", results[0] if results else \"No sufficient data\", len(discharge_text) # Return aspiration result, explanation, and length of discharge_text\n","\n","def process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file):\n","    processing_time = []\n","    with open(output_csv_file, 'a', newline='') as csvfile, open(progress_report_file, 'a') as report_file:\n","        # Open the CSV file for writing\n","        fieldnames = ['hadm_id', 'discharge_text_length', 'aspiration_detected', 'time_taken']\n","        # Define the column names\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","        # Only write header if the file is empty\n","        if csvfile.tell() == 0:\n","            writer.writeheader()  # Write the header row\n","\n","        for i in range(start_index, start_index + num_patients):\n","            current_hadm_id = df['hadm_id'].values[i]\n","            start_time = time.time()\n","            data = df[df['hadm_id'] == current_hadm_id]\n","            if data.empty:\n","                result = f\"No data found for hadm_id: {current_hadm_id}\"\n","            else:\n","                discharge_text = data['discharge_text'].values[0]\n","                aspiration_result, explanation, discharge_text_length = check_for_aspiration(discharge_text, llm, prompt_template, chunk_size, chunk_overlap)\n","                end_time = time.time()\n","                elapsed_time = end_time - start_time\n","                minutes, seconds = divmod(elapsed_time, 60)\n","                processing_time.append(elapsed_time)\n","                # Write data to CSV file\n","                writer.writerow({\n","                    'hadm_id': current_hadm_id,\n","                    'discharge_text_length': discharge_text_length,\n","                    'aspiration_detected': aspiration_result,\n","                    'time_taken': round(elapsed_time)\n","                })\n","                csvfile.flush()  # Flush the buffer to ensure data is written\n","\n","                # Write data to progress report file\n","                report_file.write(f\"Patient Number: {i}, HADM ID: {current_hadm_id}, Discharge Text Length: {discharge_text_length}, Aspiration Detected: {aspiration_result}, Time Taken: {round(elapsed_time)}\\n\")\n","                report_file.flush()  # Flush the buffer to ensure data is written\n","\n","                print(f\"Processed Patient Number {i}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"ORCYXTq6HkBj"},"source":["# Main (calls all the functions above)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99149,"status":"ok","timestamp":1717685108282,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"hpG2CYKdHjrr","outputId":"e1465643-368c-4436-cf42-699c5a4b1542"},"outputs":[{"name":"stdout","output_type":"stream","text":["NoNo.NoProcessed Patient Number 2001\n","\n","No.NoNoYesNo.Processed Patient Number 2002\n","\n","No.No.YesNo.No.Processed Patient Number 2003\n","\n","NoNoNoYesYesProcessed Patient Number 2004\n","\n","NoNo.NoProcessed Patient Number 2005\n","\n","NoNo.Processed Patient Number 2006\n","\n","No.NoYesNoNoProcessed Patient Number 2007\n","\n","No.NoNoNoYesNoNoProcessed Patient Number 2008\n","\n","NoNoNoNo.No.Processed Patient Number 2009\n","\n","NoNoYesNoProcessed Patient Number 2010\n","\n","NoNoNoYesNoNo.NoProcessed Patient Number 2011\n","\n","NoNo.NoNoNoNoProcessed Patient Number 2012\n","\n","NoNoNoNoProcessed Patient Number 2013\n","\n","No.NoNo.Processed Patient Number 2014\n","\n","No.NoYesNoNo.NoYesNoProcessed Patient Number 2015\n","\n","NoNo.Processed Patient Number 2016\n","\n","No.NoNoNoProcessed Patient Number 2017\n","\n","NoNoNoNoProcessed Patient Number 2018\n","\n","NoNoNoNoNoNoProcessed Patient Number 2019\n","\n","No.NoNoProcessed Patient Number 2020\n","\n"]}],"source":["def main(file_path, model_name, chunk_size, chunk_overlap, output_csv_file, progress_report_file, num_patients):\n","    df = load_data(file_path)\n","    #start_index = select_random_start(len(df))\n","    start_index = 2001\n","    prompt_template = create_prompt_template()\n","    llm = Ollama(model=model_name, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n","    process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file)\n","\n","if __name__ == \"__main__\":\n","    main(\n","        file_path='/content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv',\n","        model_name=\"llama3\",\n","        chunk_size=4096,\n","        chunk_overlap=100,\n","        output_csv_file='aspiration-trial-2020.csv',  # Change the output file name to a CSV file\n","        progress_report_file='aspiration-trial-2020.txt',  # Path to the progress report file\n","        num_patients = 20\n","    )\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMyPbyE3B+meLCqic8qty+k","gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
