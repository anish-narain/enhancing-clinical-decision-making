{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOYnnK4voaJAS06g/U6jrFN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Dependencies"],"metadata":{"id":"C0HKuIqz6mak"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VbkI4zR6MOl","executionInfo":{"status":"ok","timestamp":1717756555457,"user_tz":-60,"elapsed":4476,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"}},"outputId":"5708dd01-91ba-4679-8e68-b80b56f9eec3"},"outputs":[{"output_type":"stream","name":"stdout","text":[">>> Downloading ollama...\n","############################################################################################# 100.0%\n",">>> Installing ollama to /usr/local/bin...\n",">>> Creating ollama user...\n",">>> Adding ollama user to video group...\n",">>> Adding current user to ollama group...\n",">>> Creating ollama systemd service...\n","WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n"]}],"source":["!curl -fsSL https://ollama.com/install.sh | sh"]},{"cell_type":"markdown","source":["Inside terminal run the following:\n","\n","```\n","ollama serve &\n","ollama run llama3\n","```\n","\n","\n","\n","\n"],"metadata":{"id":"J83CiHJ28ywv"}},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDly6F4x70cy","executionInfo":{"status":"ok","timestamp":1717756671491,"user_tz":-60,"elapsed":12244,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"}},"outputId":"92d61a98-e733-40c8-bd9f-2f46aeedf959"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_community\n","  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n","Collecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n","  Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n","  Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n","  Downloading langsmith-0.1.75-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n","  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.3)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.3 langchain-core-0.2.5 langchain-text-splitters-0.2.1 langchain_community-0.2.4 langsmith-0.1.75 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["# Load Google Drive because it stores /content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBKxocof9Hyz","executionInfo":{"status":"ok","timestamp":1717756693536,"user_tz":-60,"elapsed":18012,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"}},"outputId":"ee208d3f-99f2-4183-d15f-907b4ad29e84"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"ZYn-iYTa6ycW"}},{"cell_type":"code","source":["import pandas as pd\n","import time\n","import random\n","import csv\n","from langchain_community.llms import Ollama\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain_core.prompts import PromptTemplate"],"metadata":{"id":"lMw0VBWN9DkQ","executionInfo":{"status":"ok","timestamp":1717756697189,"user_tz":-60,"elapsed":1282,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Functions to load data, specify LLM prompt, and perform LLM inference"],"metadata":{"id":"HWQhLQDK638b"}},{"cell_type":"code","source":["def load_data(file_path):\n","    df = pd.read_csv(file_path)\n","    df.fillna('', inplace=True)\n","    return df\n","\n","def select_random_start(num_rows, min_rows=15):\n","    if num_rows < min_rows:\n","        raise ValueError(f\"The dataset must contain at least {min_rows} rows to process.\")\n","    return random.randint(0, num_rows - min_rows)\n","\n","def create_prompt_template():\n","    return PromptTemplate(\n","        template=(\n","            \"Context: You are a clinician receiving chunks of clinical text for patients in an ICU. Please do the reviewing as quickly as possible.\\n\"\n","            \"Task: Determine if the patient suffered from cardiac arrest.\\n\"\n","            \"Instructions: Answer with 'Yes' or 'No'. If there is not enough information, answer 'No'.\\n\"\n","            \"Discharge Text:\\n{discharge_text}\\n\\n\"\n","            \"Query: Does the chunk of text mention that the patient suffered from cardiac arrest? Answer strictly in 'Yes' or 'No'.\"\n","        ),\n","        input_variables=[\"discharge_text\"]\n","    )\n","\n","def chunk_text(text, chunk_size, overlap):\n","    start = 0\n","    chunks = []\n","    while start < len(text):\n","        end = start + chunk_size\n","        chunks.append(text[start:end])\n","        start += chunk_size - overlap\n","    return chunks\n","\n","def check_for_cardiac_arrest(discharge_text, llm, prompt_template, chunk_size, chunk_overlap):\n","    chunks = chunk_text(discharge_text, chunk_size, chunk_overlap)\n","    results = []\n","    for chunk in chunks:\n","        prompt = prompt_template.format(discharge_text=chunk)\n","        try:\n","            response = llm.invoke(prompt)\n","            results.append(response.strip())\n","        except Exception as e:\n","            results.append(f\"Error invoking model: {e}\")\n","    cardiac_arrest_mentions = [res for res in results if \"Yes\" in res]\n","    if cardiac_arrest_mentions:\n","        return \"Yes\", cardiac_arrest_mentions[0], len(discharge_text) # Return cardiac_arrest result, explanation, and length of discharge_text\n","    else:\n","        return \"No\", results[0] if results else \"No sufficient data\", len(discharge_text) # Return cardiac_arrest result, explanation, and length of discharge_text\n","\n","def process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file):\n","    processing_time = []\n","    with open(output_csv_file, 'a', newline='') as csvfile, open(progress_report_file, 'a') as report_file:\n","        # Open the CSV file for writing\n","        fieldnames = ['hadm_id', 'discharge_text_length', 'cardiac_arrest_detected', 'time_taken']\n","        # Define the column names\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","        # Only write header if the file is empty\n","        if csvfile.tell() == 0:\n","            writer.writeheader()  # Write the header row\n","\n","        for i in range(start_index, start_index + num_patients):\n","            current_hadm_id = df['hadm_id'].values[i]\n","            start_time = time.time()\n","            data = df[df['hadm_id'] == current_hadm_id]\n","            if data.empty:\n","                result = f\"No data found for hadm_id: {current_hadm_id}\"\n","            else:\n","                discharge_text = data['discharge_text'].values[0]\n","                cardiac_arrest_result, explanation, discharge_text_length = check_for_cardiac_arrest(discharge_text, llm, prompt_template, chunk_size, chunk_overlap)\n","                end_time = time.time()\n","                elapsed_time = end_time - start_time\n","                minutes, seconds = divmod(elapsed_time, 60)\n","                processing_time.append(elapsed_time)\n","                # Write data to CSV file\n","                writer.writerow({\n","                    'hadm_id': current_hadm_id,\n","                    'discharge_text_length': discharge_text_length,\n","                    'cardiac_arrest_detected': cardiac_arrest_result,\n","                    'time_taken': round(elapsed_time)\n","                })\n","                csvfile.flush()  # Flush the buffer to ensure data is written\n","\n","                # Write data to progress report file\n","                report_file.write(f\"Patient Number: {i}, HADM ID: {current_hadm_id}, Discharge Text Length: {discharge_text_length}, Cardiac Arrest Detected: {cardiac_arrest_result}, Time Taken: {round(elapsed_time)}\\n\")\n","                report_file.flush()  # Flush the buffer to ensure data is written\n","\n","                print(f\"Processed Patient Number {i}\\n\")"],"metadata":{"id":"PYC4wFzh64z-","executionInfo":{"status":"ok","timestamp":1717756937143,"user_tz":-60,"elapsed":270,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Main (calls all the functions above)"],"metadata":{"id":"eq5VseRR7Dfe"}},{"cell_type":"code","source":["def main(file_path, model_name, chunk_size, chunk_overlap, output_csv_file, progress_report_file, num_patients):\n","    df = load_data(file_path)\n","    # start_index = select_random_start(len(df))\n","    start_index = 2020\n","    prompt_template = create_prompt_template()\n","    llm = Ollama(model=model_name, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n","    process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file)\n","\n","if __name__ == \"__main__\":\n","    main(\n","        file_path='/content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv',\n","        model_name=\"llama3\",\n","        chunk_size=4096,\n","        chunk_overlap=100,\n","        output_csv_file='cardiac-arrest-2020.csv',  # Change the output file name to a CSV file\n","        progress_report_file='cardiac-arrest-2020.txt',  # Path to the progress report file\n","        num_patients = 1\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahusYxXm9kK8","executionInfo":{"status":"ok","timestamp":1717763440645,"user_tz":-60,"elapsed":4474,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"}},"outputId":"edb8a87c-0f37-4bee-fc8f-69ec82f69b69"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["NoNoNo.Processed Patient Number 2020\n","\n"]}]}]}