{"cells":[{"cell_type":"markdown","metadata":{"id":"C0HKuIqz6mak"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4596,"status":"ok","timestamp":1717679882180,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"8VbkI4zR6MOl","outputId":"228f9a29-2424-41a9-d454-a18fd6e6ac41"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Downloading ollama...\n","############################################################################################# 100.0%\n",">>> Installing ollama to /usr/local/bin...\n",">>> Creating ollama user...\n",">>> Adding ollama user to video group...\n",">>> Adding current user to ollama group...\n",">>> Creating ollama systemd service...\n","WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n"]}],"source":["!curl -fsSL https://ollama.com/install.sh | sh"]},{"cell_type":"markdown","metadata":{"id":"J83CiHJ28ywv"},"source":["Inside terminal run the following:\n","\n","```\n","ollama serve &\n","ollama run llama3\n","```\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12394,"status":"ok","timestamp":1717680069910,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"iDly6F4x70cy","outputId":"d12699de-ab6e-4dca-e78a-c0d7c47eac15"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_community\n","  Downloading langchain_community-0.2.3-py3-none-any.whl (2.2 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n","Collecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n","  Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n","  Downloading langchain_core-0.2.4-py3-none-any.whl (310 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n","  Downloading langsmith-0.1.74-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n","  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.3)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.2 langchain-core-0.2.4 langchain-text-splitters-0.2.1 langchain_community-0.2.3 langsmith-0.1.74 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain_community"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28792,"status":"ok","timestamp":1717680164556,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"YBKxocof9Hyz","outputId":"7408c485-7b4d-4a00-88ac-95fc920f31ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Load Google Drive because it stores /content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ZYn-iYTa6ycW"},"source":["# Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1781,"status":"ok","timestamp":1717680940009,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"lMw0VBWN9DkQ"},"outputs":[],"source":["import pandas as pd\n","import time\n","import random\n","import csv\n","from langchain_community.llms import Ollama\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain_core.prompts import PromptTemplate"]},{"cell_type":"markdown","metadata":{"id":"HWQhLQDK638b"},"source":["# Functions to load data, specify LLM prompt, and perform LLM inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYC4wFzh64z-"},"outputs":[],"source":["def load_data(file_path):\n","    df = pd.read_csv(file_path)\n","    df.fillna('', inplace=True)\n","    return df\n","\n","def select_random_start(num_rows, min_rows=15):\n","    if num_rows < min_rows:\n","        raise ValueError(f\"The dataset must contain at least {min_rows} rows to process.\")\n","    return random.randint(0, num_rows - min_rows)\n","\n","def create_prompt_template():\n","    return PromptTemplate(\n","        template=(\n","            \"Context: You are a clinician receiving chunks of clinical text for patients in an ICU. Please do the reviewing as quickly as possible.\\n\"\n","            \"Task: Determine if the patient had pneumonia.\\n\"\n","            \"Instructions: Answer with 'Yes' or 'No'. If there is not enough information, answer 'No'.\\n\"\n","            \"Discharge Text:\\n{discharge_text}\\n\\n\"\n","            \"Query: Does the chunk of text suggest that the patient has pneumonia? Answer strictly in 'Yes' or 'No'.\"\n","        ),\n","        input_variables=[\"discharge_text\"]\n","    )\n","\n","def chunk_text(text, chunk_size, overlap):\n","    start = 0\n","    chunks = []\n","    while start < len(text):\n","        end = start + chunk_size\n","        chunks.append(text[start:end])\n","        start += chunk_size - overlap\n","    return chunks\n","\n","def check_for_pneumonia(discharge_text, llm, prompt_template, chunk_size, chunk_overlap):\n","    chunks = chunk_text(discharge_text, chunk_size, chunk_overlap)\n","    results = []\n","    for chunk in chunks:\n","        prompt = prompt_template.format(discharge_text=chunk)\n","        try:\n","            response = llm.invoke(prompt)\n","            results.append(response.strip())\n","        except Exception as e:\n","            results.append(f\"Error invoking model: {e}\")\n","    pneumonia_mentions = [res for res in results if \"Yes\" in res]\n","    if pneumonia_mentions:\n","        return \"Yes\", pneumonia_mentions[0], len(discharge_text) # Return pneumonia result, explanation, and length of discharge_text\n","    else:\n","        return \"No\", results[0] if results else \"No sufficient data\", len(discharge_text) # Return pneumonia result, explanation, and length of discharge_text\n","\n","def process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file):\n","    processing_time = []\n","    with open(output_csv_file, 'a', newline='') as csvfile, open(progress_report_file, 'a') as report_file:\n","        # Open the CSV file for writing\n","        fieldnames = ['hadm_id', 'discharge_text_length', 'pneumonia_detected', 'time_taken']\n","        # Define the column names\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","        # Only write header if the file is empty\n","        if csvfile.tell() == 0:\n","            writer.writeheader()  # Write the header row\n","\n","        for i in range(start_index, start_index + num_patients):\n","            current_hadm_id = df['hadm_id'].values[i]\n","            start_time = time.time()\n","            data = df[df['hadm_id'] == current_hadm_id]\n","            if data.empty:\n","                result = f\"No data found for hadm_id: {current_hadm_id}\"\n","            else:\n","                discharge_text = data['discharge_text'].values[0]\n","                pneumonia_result, explanation, discharge_text_length = check_for_pneumonia(discharge_text, llm, prompt_template, chunk_size, chunk_overlap)\n","                end_time = time.time()\n","                elapsed_time = end_time - start_time\n","                minutes, seconds = divmod(elapsed_time, 60)\n","                processing_time.append(elapsed_time)\n","                # Write data to CSV file\n","                writer.writerow({\n","                    'hadm_id': current_hadm_id,\n","                    'discharge_text_length': discharge_text_length,\n","                    'pneumonia_detected': pneumonia_result,\n","                    'time_taken': round(elapsed_time)\n","                })\n","                csvfile.flush()  # Flush the buffer to ensure data is written\n","\n","                # Write data to progress report file\n","                report_file.write(f\"Patient Number: {i}, HADM ID: {current_hadm_id}, Discharge Text Length: {discharge_text_length}, Pneumonia Detected: {pneumonia_result}, Time Taken: {round(elapsed_time)}\\n\")\n","                report_file.flush()  # Flush the buffer to ensure data is written\n","\n","                print(f\"Processed Patient Number {i}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"eq5VseRR7Dfe"},"source":["# Main (calls all the functions above)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":5355,"status":"error","timestamp":1717683418422,"user":{"displayName":"Anish Narain","userId":"17681602453754587772"},"user_tz":-60},"id":"ahusYxXm9kK8","outputId":"0dd578ef-1431-402b-cf00-2b3ad9ec8f6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["YesYesYesProcessed Patient Number 2020\n","\n"]},{"ename":"IndexError","evalue":"index 2021 is out of bounds for axis 0 with size 2021","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-28ce9a32e39d>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     main(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llama3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-28ce9a32e39d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(file_path, model_name, chunk_size, chunk_overlap, output_csv_file, progress_report_file, num_patients)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mprompt_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_prompt_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOllama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStreamingStdOutCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mprocess_patients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_patients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_overlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_report_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-28ce9a32e39d>\u001b[0m in \u001b[0;36mprocess_patients\u001b[0;34m(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_patients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mcurrent_hadm_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hadm_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hadm_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_hadm_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 2021 is out of bounds for axis 0 with size 2021"]}],"source":["def main(file_path, model_name, chunk_size, chunk_overlap, output_csv_file, progress_report_file, num_patients):\n","    df = load_data(file_path)\n","    #start_index = select_random_start(len(df))\n","    start_index = 2020\n","    prompt_template = create_prompt_template()\n","    llm = Ollama(model=model_name, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n","    process_patients(df, start_index, num_patients, llm, prompt_template, chunk_size, chunk_overlap, output_csv_file, progress_report_file)\n","\n","if __name__ == \"__main__\":\n","    main(\n","        file_path='/content/drive/My Drive/ards-cohort-notes/ards-cohort-notes.csv',\n","        model_name=\"llama3\",\n","        chunk_size=4096,\n","        chunk_overlap=100,\n","        output_csv_file='pneumonia-without-gpu.csv',  # Change the output file name to a CSV file\n","        progress_report_file='pneumonia-without-gpu.txt',  # Path to the progress report file\n","        num_patients = 2\n","    )\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNdSdj+G6cCQobqgfST2kUr","gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
